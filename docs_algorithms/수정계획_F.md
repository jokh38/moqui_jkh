물론입니다. 제안해주신 모든 내용을 종합하여, 신규 개발자가 이 문서 하나만으로 프로젝트의 모든 배경과 기술적 깊이를 이해하고 실제 개발을 수행할 수 있도록, 최종 통합 개발 계획서를 재작성해 드리겠습니다.

-----

## MOQUI 차세대 GPU 수송 엔진 개발 계획서 (v4.0 Final)

**문서 개요:** 이 문서는 MOQUI의 기존 입자 수송 엔진을 차세대 고성능 엔진으로 전환하기 위한 종합적인 개발 계획을 담고 있습니다. 배경 이론, 단계별 개발 전략, 핵심 최적화 기법, 구체적인 코드 수정 지침 및 최종 성능 목표를 포함하며, 신규 개발자를 위한 유일한 정보 공급원(Single Source of Truth) 역할을 합니다.

### 1\. 개발 배경 및 최종 비전

#### 1.1. 배경: 정확도와 속도의 패러다임

방사선 입자 수송 시뮬레이션은 계산 방식에 따라 \*\*'응축 이력(Condensed History)'\*\*과 **'개별 사건(Event-by-Event)'** 두 가지로 나뉩니다. 이 두 방식의 이해는 본 프로젝트의 당위성과 직결됩니다.

| 항목 | 응축 이력 (Condensed History) | 개별 사건 (Event-by-Event) |
| :--- | :--- | :--- |
| **개념** | 다수의 물리적 상호작용을 통합하여 하나의 긴 스텝(step)으로 근사 계산합니다. | 모든 물리적 상호작용을 개별적으로 확률론에 기반해 정밀 추적합니다. |
| **장점** | 거시적(macroscopic) 선량 계산에 **매우 빠릅니다.** | 나노스케일(nanoscale) 물리 과정의 **정확도가 매우 높습니다.** |
| **단점** | DNA와 같은 미세 구조 내 개별 상호작용 추적은 불가능합니다. | CPU 기반으로 수행 시 **계산 속도가 극단적으로 느립니다.** |
| **현재 MOQUI** | 이 방식을 사용하여 임상 환경에서 빠른 속도를 확보했습니다. | - |

'개별 사건' 방식의 높은 정확도는 매우 매력적이지만, 이를 GPU 환경에 그대로 적용할 경우 심각한 성능 저하를 유발합니다. 이는 GPU 아키텍처의 고유한 특성 때문입니다.

  - **무작위 메모리 접근 (Random Memory Access)**: 수백만 개의 입자(스레드)가 각기 다른 에너지 상태에 따라 물리 데이터 테이블의 서로 다른 위치를 참조하게 되어 캐시 효율이 급격히 떨어집니다.
  - **스레드 분기 (Thread Divergence)**: GPU는 32개 스레드를 한 묶음(warp)으로 묶어 동일한 명령을 실행합니다. 만약 이 스레드들이 서로 다른 물리 현상을 겪어 실행 경로가 갈라지면, GPU는 이 모든 경로를 순차적으로 실행해야 하므로 병렬 처리의 이점을 상실하게 됩니다.

#### 1.2. 최종 목표: GPU 네이티브 `Event-by-Event` 엔진 구현

이번 개발의 최종 목표는 위에서 언급한 GPU의 구조적 한계를 극복하는, **GPU 네이티브(Native) `Event-by-Event` 수송 커널을 개발**하는 것입니다. 이 엔진은 단순한 코드 이식이 아닌, GPU 아키텍처를 완벽하게 활용하는 새로운 차원의 설계를 지향합니다.

이를 위해 **고급 메모리 관리 기법**과 **지능형 알고리즘 최적화**를 적용하여 '개별 사건' 방식의 정확도를 유지하면서도 기존 CPU 방식 대비 수천 배 빠른 성능을 달성하고자 합니다. 또한, 필요에 따라 임상 선량 계산에 적합한 \*\*고속화 모드(에너지 컷오프)\*\*를 선택할 수 있는 유연성을 제공하여, 단일 엔진으로 정밀 연구와 빠른 임상 계산을 모두 지원하는 것을 비전으로 삼습니다.

### 2\. 단계적 개발 전략 (Phased Implementation)

프로젝트의 복잡성을 관리하고 리스크를 최소화하기 위해, 다음과 같은 3단계 개발 전략을 채택합니다. 각 단계는 독립적으로 성능을 검증하고, 성공 시 다음 단계로 진행합니다.

| 단계 | 목표 | 핵심 기술 | 예상 누적 성능 향상 |
| :--- | :--- | :--- | :--- |
| **Phase 1** | **빠른 성능 개선 및 기반 기술 검증** | **텍스처 메모리** 적용 | **1.5 \~ 2.0배** |
| **Phase 2** | **핵심 알고리즘 최적화 및 효과 극대화** | **적응형 입자 재정렬** 추가 | **2.2 \~ 4.0배** |
| **Phase 3** | **`Event-by-Event` 커널 통합 및 고급 최적화** | **신규 커널 및 고급 기법** 적용 | **현실적 3\~4배, 최선 5\~8배** |

-----

### 3\. Phase 1: 텍스처 메모리 적용 (기반 기술 구현)

**목표**: 기존 `Condensed History` 커널의 물리 데이터 접근 방식을 개선하여 즉각적인 성능 향상을 달성하고, 향후 개발의 기반을 다집니다.

  - **핵심 기술: 텍스처 메모리(Texture Memory) 활용**

      - **원리**: 물리 데이터(상호작용 단면적, 저지능 등)를 일반 전역 메모리가 아닌 2D 텍스처 메모리에 바인딩합니다.
      - **기대 효과**:
        1.  **하드웨어 가속 보간**: 입자의 에너지가 테이블에 없는 값일 경우, 텍스처 하드웨어가 주변 값들을 이용해 필요한 값을 \*\*자동으로 선형 보간(Linear Interpolation)\*\*하여 소프트웨어 보간보다 월등히 빠릅니다.
        2.  **전용 캐시**: 텍스처 메모리는 그래픽 처리에 최적화된 별도의 L1 캐시를 사용하며, 특히 \*\*공간적 지역성(spatial locality)\*\*이 있는 데이터 접근(예: 비슷한 에너지의 입자들이 테이블의 인접 영역에 접근)에 매우 효율적입니다.

  - **구현 지침**:

    1.  **신규 클래스 작성 (`physics/mqi_physics_data.hpp`, `.cu`)**: 물리 데이터를 로드하고, GPU 메모리에 복사한 뒤 CUDA 텍스처 객체로 생성 및 관리하는 `physics_data_manager` 클래스를 구현합니다.
    2.  **커널 수정 (`kernel_functions/mqi_transport.hpp`)**: 기존 `transport_particles_patient` 커널 내에서 물리 데이터를 직접 배열에서 읽어오던 부분을, 생성된 텍스처 객체를 통해 `tex2D()` 함수로 조회하도록 수정합니다.

-----

### 4\. Phase 2: 적응형 입자 재정렬 (핵심 성능 최적화)

**목표**: Phase 1의 결과물에 입자 재정렬 알고리즘을 추가하여 스레드 분기 및 비병합 메모리 접근 문제를 해결하고, GPU 활용률을 극대화합니다.

  - **핵심 기술: 주기적/적응형 입자 재정렬 (Particle Sorting)**

      - **원리**: 수송 커널 실행 직전에, GPU 상의 전체 입자 배열을 **에너지 순(내림차순)으로 정렬**합니다. 이를 통해 한 워프(warp) 내의 스레드들이 유사한 에너지의 입자를 처리하게 만듭니다.
      - **기대 효과**:
        1.  **스레드 분기 최소화**: 유사한 에너지의 입자들은 비슷한 물리 과정을 겪을 확률이 높아져 실행 경로가 통일됩니다. 이는 GPU의 SIMT 아키텍처 활용도를 최고 수준으로 끌어올립니다.
        2.  **메모리 접근 패턴 개선 (Coalescing)**: 정렬된 입자들은 물리 테이블의 거의 동일한 영역에 동시 접근하게 되므로, Phase 1에서 도입한 텍스처 캐시의 히트율이 극대화됩니다.

  - **구현 지침**:

    1.  **메인 루프 수정 (`base/mqi_treatment_session.cpp`)**: 단일 커널 호출 구조를 `while` 루프로 변경하고, 루프의 시작 부분에 **Thrust 라이브러리**를 사용한 병렬 정렬 로직을 추가합니다.
        ```cpp
        #include <thrust/sort.h>
        #include <thrust/execution_policy.h>

        while (/* 입자가 남아있는 동안 */) {
            // [지능형 최적화]
            // if (분기율 > 임계치) { // 주기적으로 워프 분기율을 모니터링
            //     thrust::sort(thrust::device, d_tracks, d_tracks + n, by_energy());
            // }
            transport_particles_patient<<<...>>>(...);
        }
        ```
    2.  **지능형 최적화: 적응적 정렬 (Adaptive Sorting)**: 매번 정렬하는 대신, 워프 분기율을 측정하는 간단한 프로파일링 코드를 추가합니다. 분기율이 설정된 임계치를 초과할 때만 정렬을 수행하여, 불필요한 정렬 오버헤드를 줄이고 순수 성능 향상을 극대화합니다.

-----

### 5\. Phase 3: `Event-by-Event` 커널 통합 및 고급 최적화

**목표**: Phase 1, 2에서 검증된 최적화 기법을 총동원하여, 최종 목표인 고성능 `Event-by-Event` 수송 커널을 개발하고 기존 커널을 대체합니다.

  - **신규 커널 작성 (`kernel_functions/mqi_transport_event.hpp`)**: `transport_event_by_event_kernel`이라는 새로운 커널을 작성합니다. 이 커널은 다음과 같은 고급 기법들을 포함합니다.

| 기술 | 상세 내용 및 구현 지침 |
| :--- | :--- |
| **1. Woodcock 트래킹** | 복잡한 CT 지오메트리에서 반복적인 복셀 경계 계산을 피하기 위해 도입합니다. **구현**: 1) 전체 물질 중 가장 높은 총 단면적(`max_sigma`)을 미리 계산합니다. 2) 입자는 이 `max_sigma`를 기준으로 가상의 평균자유행로(MFP)만큼 이동합니다. 3) 이동한 위치에서 `실제 단면적 / max_sigma` 확률로 실제 상호작용 여부를 결정(rejection sampling)합니다. 실제 상호작용이 아니면 '가상 상호작용'으로 처리하고 그대로 직진합니다. |
| **2. 공유 메모리 기반 스택** | 2차 입자 관리를 위해 스레드 블록 내에 `__shared__ track_t secondary_stack[256];`와 같이 스택을 구현합니다. 전역 메모리보다 100배 빠른 접근 속도로 잦은 push/pop 오버헤드를 최소화하고, '작업 훔치기(Work Stealing)'를 구현하여 부하를 분산시킵니다. |
| **3. 워프 레벨 프리미티브** | 공유 메모리보다 더 빠른 레지스터 간 직접 통신을 위해 `__shfl_sync()`와 같은 내장 함수를 활용합니다. **예시**: 워프 내에서 선량을 합산하거나 특정 스레드의 값을 모든 스레드로 방송(broadcast)할 때 사용하여 메모리 접근을 원천적으로 제거합니다. |
| **4. 동적 병렬처리** | 2차 입자가 폭증하는 특정 이벤트에 대응하기 위해 CUDA의 동적 병렬처리를 검토합니다. **구현**: 커널 내에서 생성된 2차 입자의 수가 임계치를 초과할 경우, 해당 입자들을 처리하는 별도의 자식 커널을 스레드가 직접 호출하여 작업을 위임합니다. (`process_secondaries<<<1, 32>>>(...)`) |
| **5. 지능형 에너지 컷오프** | 임상 계산 고속화를 위해 에너지 컷오프를 적용하되, 고정값이 아닌 물질별로 다른 값을 적용합니다. **구현**: 뼈처럼 밀도가 높은 물질에서는 비정이 짧으므로 더 높은 에너지에서, 폐처럼 밀도가 낮은 물질에서는 더 낮은 에너지에서 컷오프를 적용하도록 하여 정확도 손실 없이 효율을 극대화합니다. |

  - **최종 제어 로직 구현 (`base/mqi_treatment_session.hpp`, `.cpp`)**:
    1.  사용자가 moqui_tps.in 설정에서 `transport_model`을 `CONDENSED_HISTORY` 또는 `EVENT_BY_EVENT`로 선택할 수 있도록 `enum` 클래스를 추가합니다.
    2.  `run_simulation` 함수 내에서 이 설정에 따라 Phase 2에서 수정한 기존 커널 또는 Phase 3에서 새로 개발한 커널을 선택적으로 호출하도록 분기 로직을 작성합니다.

### 6\. 최종 성능 예측 (모든 제안 반영 시)

이 계획서의 모든 단계와 최적화 기법이 성공적으로 통합되었을 때, MOQUI의 성능은 다음과 같이 비약적으로 향상될 것입니다.

  - **현실적 시나리오: 3 \~ 4배 속도 향상**
      - 핵심 최적화 기법들이 완벽히 구현되어 안정적으로 동작하는 경우입니다. 이는 기존 MOQUI 대비 압도적인 성능 향상이며, 임상 및 연구 양면에서 매우 강력한 경쟁력을 확보하게 됨을 의미합니다.
  - **최선 시나리오: 5 \~ 8배 속도 향상**
      - Woodcock 트래킹, 적응적 정렬 등 모든 고급 최적화가 이상적으로 작동하고, 특히 CT 데이터의 복잡한 경계면에서 높은 효율을 보이는 경우입니다. 이는 FRED와 같은 세계 최고 수준의 상용 소프트웨어 성능에 근접하는 것을 의미합니다.
  - **최악 시나리오: 1.5 \~ 2배 속도 향상**
      - 단계적 접근 방식을 통해 최악의 경우에도 Phase 1의 성능 향상은 보장됩니다. 이는 프로젝트의 안정성을 담보하는 중요한 안전장치입니다.

이 문서는 MOQUI를 세계 최고 수준의 GPU 몬테카를로 시뮬레이션 엔진으로 발전시키기 위한 종합적인 청사진입니다. 개발자는 본 문서의 단계적 전략과 구체적인 지침을 충실히 따라주시길 바랍니다.